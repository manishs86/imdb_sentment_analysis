{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10ebc00f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from  tqdm import tqdm\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "import re\n",
    "from torchtext import vocab as vc\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imdb_dir = '/Users/sampath/dlProjects/imdb_sent/aclImdb'\n",
    "train_dir = os.path.join(imdb_dir, 'train')\n",
    "test_dir = os.path.join(imdb_dir, 'test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for reading the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load the each text into texts list\n",
    "## corresponding label will be in labels list. \n",
    "def read_test_train_dir(path,):\n",
    "    labels = []\n",
    "    texts = []\n",
    "    for label_type in ['neg', 'pos']:\n",
    "        dir_name = os.path.join(train_dir, label_type)\n",
    "        for fname in os.listdir(dir_name):\n",
    "            if fname[-4:] == '.txt':\n",
    "                f = open(os.path.join(dir_name, fname))\n",
    "                texts.append(f.read())\n",
    "                f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "    return texts,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the test and train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_texts,train_labels = read_test_train_dir(train_dir)\n",
    "test_texts, test_labels = read_test_train_dir(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for tokenizing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_paragraph_words(text):\n",
    "    return (flatten([word_tokenize(s) for s in sent_tokenize(text)]))\n",
    "\n",
    "sent_tokenize = nltk.sent_tokenize\n",
    "word_tokenize = RegexpTokenizer(r'\\w+').tokenize\n",
    "\n",
    "def word_tokenize_para(text):\n",
    "    return [word_tokenize(s) for s in sent_tokenize(text)]\n",
    "\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the vocabulary counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_counter = Counter(flatten([get_paragraph_words(text) for text in train_texts]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93929"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the glove word vectors  100 dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get w2v populated for vocabulary\n",
    "w2v = vc.Vocab(vocab_counter,max_size=20000,min_freq=3,vectors='glove.6B.100d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random shuffle test and train data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomly shuffle the training data\n",
    "training_set = list(zip(train_texts,train_labels))\n",
    "#shuffle works inplace and returns None . \n",
    "random.shuffle(training_set)\n",
    "\n",
    "# randomly shuffle the training data\n",
    "testing_set  = list(zip(test_texts,test_labels))\n",
    "#shuffle works inplace and returns None . \n",
    "random.shuffle(testing_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since average sentence length is 246 words, setting sequence length to 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxSeqLength = 250\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to get w2v from review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to get vocabular indices from text returns list of indices (cut-off at maxSeqLength)\n",
    "def stoiForReview(w2v, text,maxSeqLength):\n",
    "    #trim the sentence to maxSeqLength, otherwise return with original length. \n",
    "    return [w2v.stoi[word] for word in get_paragraph_words(text)[0:maxSeqLength]]\n",
    "\n",
    "#function to get word vectors for review - returns tensor of size 1, min(len(review),maxSeqLength),embedded_dim\n",
    "def wordVectorsForReview(w2v,text,maxSeqLength):\n",
    "    indexes = stoiForReview(w2v, text,maxSeqLength)\n",
    "    #returns tensor with size [num_words,1,embedding_dim]\n",
    "    #That extra 1 dimension is because PyTorch assumes everything is in batches - weâ€™re just using a batch size of 1 here.\n",
    "    sent_word_vectors = torch.cat([w2v.vectors[i].view(1,-1) for i in indexes]).view(len(indexes),1,-1)\n",
    "    \n",
    "    #batch first (1,seq_len,embedding_dim)\n",
    "    #seq_len has been maximized to maxSeqLength\n",
    "    sent_word_vectors = sent_word_vectors.view(1,len(sent_word_vectors),-1)\n",
    "    \n",
    "    return sent_word_vectors \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get data from start index (str_idx) to end index (end_idx) from list of data points give in t_set\n",
    "#### function returns two tensors - first packed_padded_sequence with input w2v and labels variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create nn.Emedding for easy lookup\n",
    "idx2vec = w2v.vectors;\n",
    "embedding = nn.Embedding(idx2vec.shape[0],idx2vec.shape[1])\n",
    "embedding.weight = nn.Parameter(idx2vec) \n",
    "embedding.weight.requires_grad = False\n",
    "\n",
    "def get_batch2(t_set,str_idx,end_idx):\n",
    "        training_batch_set = t_set[str_idx:end_idx]\n",
    "        \n",
    "        input_texts,labels = zip(*training_batch_set)\n",
    "        labels = torch.LongTensor(labels)\n",
    "        input_text_ids = [stoiForReview(w2v,text,maxSeqLength) for text in input_texts]\n",
    "        seq_lens = torch.LongTensor([len(i) for i in input_text_ids])\n",
    "        padded_input_text_ids = Variable(torch.LongTensor(len(seq_lens), seq_lens.max()).zero_())\n",
    "        for idx,(seq,seqlen) in enumerate(zip(input_text_ids,seq_lens)):\n",
    "            padded_input_text_ids[idx,:seqlen] = torch.LongTensor(seq)\n",
    "            \n",
    "        #sort according seq lengths\n",
    "        seq_lens, perm_idx = seq_lens.sort(0, descending=True)\n",
    "        padded_input_text_ids = padded_input_text_ids[perm_idx]\n",
    "        labels = labels[perm_idx]\n",
    "        \n",
    "        embed = embedding(padded_input_text_ids)\n",
    "        packed_input = pack_padded_sequence(embed, seq_lens.numpy(),batch_first=True)\n",
    "\n",
    "\n",
    "        \n",
    "        return(packed_input,labels)\n",
    "        #assign each training vector to left \n",
    "        \n",
    "        #print(seq_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(t_set,str_idx,end_idx):\n",
    "        training_batch_set = t_set[str_idx:end_idx]\n",
    "        \n",
    "        input_texts,labels = zip(*training_batch_set)\n",
    "        \n",
    "        #convert texts to vectors shape - Batch(=1),seq_length(cut-off at maxSeqLength),embedded_dim\n",
    "        input_vectors = [wordVectorsForReview(w2v,text,maxSeqLength) for text in input_texts]\n",
    "        \n",
    "        #convert to variable w/ long tensor\n",
    "        labels = Variable(torch.LongTensor(labels))\n",
    "        \n",
    "        seq_lens = torch.LongTensor([i.shape[1] for i in input_vectors])\n",
    "        embedding_dim = input_vectors[0].shape[2]\n",
    "        #batch_inputs  - [batch_size, seq_len,embedding_dim]\n",
    "        batch_inputs = Variable(torch.zeros((len(seq_lens), seq_lens.max(),embedding_dim)))\n",
    "        for idx,(seq,seqlen) in enumerate(zip(input_vectors,seq_lens)):\n",
    "            batch_inputs[idx,:seqlen] = seq\n",
    "        seq_lens, perm_idx = seq_lens.sort(0, descending=True)\n",
    "        batch_inputs = batch_inputs[perm_idx]\n",
    "        batch_inputs = pack_padded_sequence(batch_inputs, seq_lens.numpy(),batch_first=True)\n",
    "        labels = labels[perm_idx]\n",
    "        return(batch_inputs,labels)\n",
    "        #assign each training vector to left \n",
    "        \n",
    "        #print(seq_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Variables, to detach them from their history.\"\"\"\n",
    "    if type(h) == Variable:\n",
    "        return Variable(h.data)\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN1 Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model -> GRU (context dimension - 64) + Logistic  + Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN1(nn.Module):\n",
    "    def __init__(self, input_dim,context_dim,num_classes):\n",
    "        super(RNN1,self).__init__()        \n",
    "        self.context_dim = context_dim;\n",
    "        # set pretrained glove embeddings for use. \n",
    "        #freeze the embeddin\n",
    "\n",
    "        self.gru = nn.GRU(input_dim,context_dim,1,bias=True,batch_first=True)\n",
    "        self.linear = nn.Linear(context_dim,num_classes);\n",
    "    def forward(self,input,hidden):\n",
    "        #use given hidden for initial_hidden_states\n",
    "        all_h, last_h = self.gru(input,hidden);\n",
    "        #since we have only 1 layer and 1 direction\n",
    "        output = self.linear(last_h[0]);\n",
    "        #return the last_h to re-feed for next batch\n",
    "        return output,last_h;\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return Variable(torch.zeros(1,batch_size, self.context_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN2 Model\n",
    "#### Bidrectional GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN2(nn.Module):\n",
    "    def __init__(self, input_dim,context_dim,num_classes):\n",
    "        super(RNN2,self).__init__()        \n",
    "        self.context_dim = context_dim;\n",
    "        self.gru = nn.GRU(input_dim,context_dim,num_layers=1,bias=True,batch_first=True,dropout=0,bidirectional=True)\n",
    "        # since we are using 2 directions\n",
    "        self.linear = nn.Linear(2*context_dim,num_classes);\n",
    "   \n",
    "    def forward(self,input,hidden):\n",
    "        #we dont need to initialize explicitly - \n",
    "        #h0 = Variable(torch.zeros(1,input.size(0),self.context_dim))\n",
    "        all_h, last_h = self.gru(input,hidden);\n",
    "        #last_h shape is 2,batch_size,context_dim (2 is for 2 directions)\n",
    "        concated_h = torch.cat([last_h[0],last_h[1]],1)\n",
    "        output = self.linear(concated_h);\n",
    "        return output,last_h;\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        #since we are using bi-directional use 2 layers. \n",
    "        return Variable(torch.zeros(2,batch_size, self.context_dim))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 50\n",
    "#num_passes = 200//batch_size\n",
    "num_passes = 25000//batch_size # number of batches with given batch_size\n",
    "num_epochs = 50 #number of times we will go through all the training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = 100 # embedding dimension\n",
    "context_dim = 50\n",
    "num_classes = 2\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "model =  RNN2(input_dim,context_dim,num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass [100/500], in epoch [0/50] Loss: 0.6398\n",
      "pass [200/500], in epoch [0/50] Loss: 0.5498\n",
      "pass [300/500], in epoch [0/50] Loss: 0.4605\n",
      "pass [400/500], in epoch [0/50] Loss: 0.4980\n",
      "pass [500/500], in epoch [0/50] Loss: 0.4671\n",
      "pass [100/500], in epoch [1/50] Loss: 0.3123\n",
      "pass [200/500], in epoch [1/50] Loss: 0.4207\n",
      "pass [300/500], in epoch [1/50] Loss: 0.4152\n",
      "pass [400/500], in epoch [1/50] Loss: 0.4363\n",
      "pass [500/500], in epoch [1/50] Loss: 0.4566\n",
      "pass [100/500], in epoch [2/50] Loss: 0.2608\n",
      "pass [200/500], in epoch [2/50] Loss: 0.3935\n",
      "pass [300/500], in epoch [2/50] Loss: 0.3881\n",
      "pass [400/500], in epoch [2/50] Loss: 0.3870\n",
      "pass [500/500], in epoch [2/50] Loss: 0.4444\n",
      "pass [100/500], in epoch [3/50] Loss: 0.2278\n",
      "pass [200/500], in epoch [3/50] Loss: 0.3733\n",
      "pass [300/500], in epoch [3/50] Loss: 0.3540\n",
      "pass [400/500], in epoch [3/50] Loss: 0.3479\n",
      "pass [500/500], in epoch [3/50] Loss: 0.4270\n",
      "pass [100/500], in epoch [4/50] Loss: 0.2074\n",
      "pass [200/500], in epoch [4/50] Loss: 0.3485\n",
      "pass [300/500], in epoch [4/50] Loss: 0.3194\n",
      "pass [400/500], in epoch [4/50] Loss: 0.3275\n",
      "pass [500/500], in epoch [4/50] Loss: 0.4123\n",
      "pass [100/500], in epoch [5/50] Loss: 0.1967\n",
      "pass [200/500], in epoch [5/50] Loss: 0.3229\n",
      "pass [300/500], in epoch [5/50] Loss: 0.2896\n",
      "pass [400/500], in epoch [5/50] Loss: 0.3115\n",
      "pass [500/500], in epoch [5/50] Loss: 0.4110\n",
      "pass [100/500], in epoch [6/50] Loss: 0.1899\n",
      "pass [200/500], in epoch [6/50] Loss: 0.2990\n",
      "pass [300/500], in epoch [6/50] Loss: 0.2638\n",
      "pass [400/500], in epoch [6/50] Loss: 0.2824\n",
      "pass [500/500], in epoch [6/50] Loss: 0.4143\n",
      "pass [100/500], in epoch [7/50] Loss: 0.1810\n",
      "pass [200/500], in epoch [7/50] Loss: 0.2748\n",
      "pass [300/500], in epoch [7/50] Loss: 0.2431\n",
      "pass [400/500], in epoch [7/50] Loss: 0.2394\n",
      "pass [500/500], in epoch [7/50] Loss: 0.4090\n",
      "pass [100/500], in epoch [8/50] Loss: 0.1708\n",
      "pass [200/500], in epoch [8/50] Loss: 0.2452\n",
      "pass [300/500], in epoch [8/50] Loss: 0.2259\n",
      "pass [400/500], in epoch [8/50] Loss: 0.1917\n",
      "pass [500/500], in epoch [8/50] Loss: 0.3889\n",
      "pass [100/500], in epoch [9/50] Loss: 0.1651\n",
      "pass [200/500], in epoch [9/50] Loss: 0.2152\n",
      "pass [300/500], in epoch [9/50] Loss: 0.2014\n",
      "pass [400/500], in epoch [9/50] Loss: 0.1493\n",
      "pass [500/500], in epoch [9/50] Loss: 0.3479\n",
      "pass [100/500], in epoch [10/50] Loss: 0.1749\n",
      "pass [200/500], in epoch [10/50] Loss: 0.1894\n",
      "pass [300/500], in epoch [10/50] Loss: 0.1648\n",
      "pass [400/500], in epoch [10/50] Loss: 0.1108\n",
      "pass [500/500], in epoch [10/50] Loss: 0.3242\n",
      "pass [100/500], in epoch [11/50] Loss: 0.2424\n",
      "pass [200/500], in epoch [11/50] Loss: 0.2220\n",
      "pass [300/500], in epoch [11/50] Loss: 0.1320\n",
      "pass [400/500], in epoch [11/50] Loss: 0.1016\n",
      "pass [500/500], in epoch [11/50] Loss: 0.2708\n",
      "pass [100/500], in epoch [12/50] Loss: 0.1925\n",
      "pass [200/500], in epoch [12/50] Loss: 0.1434\n",
      "pass [300/500], in epoch [12/50] Loss: 0.1436\n",
      "pass [400/500], in epoch [12/50] Loss: 0.0961\n",
      "pass [500/500], in epoch [12/50] Loss: 0.3836\n",
      "pass [100/500], in epoch [13/50] Loss: 0.1009\n",
      "pass [200/500], in epoch [13/50] Loss: 0.1232\n",
      "pass [300/500], in epoch [13/50] Loss: 0.0847\n",
      "pass [400/500], in epoch [13/50] Loss: 0.0912\n",
      "pass [500/500], in epoch [13/50] Loss: 0.3347\n",
      "pass [100/500], in epoch [14/50] Loss: 0.0654\n",
      "pass [200/500], in epoch [14/50] Loss: 0.0919\n",
      "pass [300/500], in epoch [14/50] Loss: 0.0603\n",
      "pass [400/500], in epoch [14/50] Loss: 0.0969\n",
      "pass [500/500], in epoch [14/50] Loss: 0.2567\n",
      "pass [100/500], in epoch [15/50] Loss: 0.0443\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3898deec863f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Forward + Backward + Optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# zero the gradient buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/dlpytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-3c606b096876>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#we dont need to initialize explicitly -\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#h0 = Variable(torch.zeros(1,input.size(0),self.context_dim))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mall_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m#last_h shape is 2,batch_size,context_dim (2 is for 2 directions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mconcated_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_h\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast_h\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/dlpytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/dlpytorch/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         )\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/dlpytorch/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutogradRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/dlpytorch/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/dlpytorch/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/dlpytorch/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mflat_hidden\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                 \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/dlpytorch/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mGRUCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mb_ih\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mgi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mgh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mi_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    #re-initialize after \n",
    "   # random.shuffle(training_set)\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    # reinitialize hidden layers to zero after each epoch\n",
    "    for i in range(num_passes):\n",
    "        str_idx = i * batch_size\n",
    "        end_idx = (i+1) * batch_size\n",
    "        inputs,labels = get_batch(training_set,str_idx,end_idx)\n",
    "        # Starting each batch, we detach the hidden state from how it was previously produced.\n",
    "        # If we didn't, the model would try backpropagating all the way to start of the dataset.\n",
    "        #hidden = repackage_hidden(hidden)\n",
    "        hidden.detach_()\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()  # zero the gradient buffer\n",
    "        outputs,hidden = model(inputs,hidden)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('pass [%d/%d], in epoch [%d/%d] Loss: %.4f' \n",
    "                   %(i+1, num_passes,epoch, num_epochs, loss.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the  training data : 93 %\n"
     ]
    }
   ],
   "source": [
    "## Test the Model on training data\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "testing_inputs,testing_labels = get_batch(training_set,0,25000)\n",
    "hidden = model.init_hidden(25000)\n",
    "\n",
    "\n",
    "outputs,hidden = model(testing_inputs,hidden)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "total = testing_labels.size(0)\n",
    "correct = (predicted == testing_labels.data).sum()\n",
    "\n",
    "\n",
    "print('Accuracy of the network on the  training data : %d %%' % (100 * correct / total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test the Model on training data\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "testing_inputs,testing_labels = get_batch(testing_set,0,25000)\n",
    "hidden = model.init_hidden(25000)\n",
    "\n",
    "\n",
    "outputs,hidden = model(testing_inputs,hidden)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "total = testing_labels.size(0)\n",
    "correct = (predicted == testing_labels.data).sum()\n",
    "\n",
    "\n",
    "print('Accuracy of the network on the  test data: %d %%' % (100 * correct / total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
